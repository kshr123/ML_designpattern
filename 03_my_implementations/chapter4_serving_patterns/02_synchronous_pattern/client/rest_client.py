#!/usr/bin/env python3
"""
RESTã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

TensorFlow Servingã®REST APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
HTTP/JSONãƒ™ãƒ¼ã‚¹ãªã®ã§å®Ÿè£…ãŒã‚·ãƒ³ãƒ—ãƒ«ã§ã™ãŒã€gRPCã‚ˆã‚Šã¯é…ã„ã§ã™ã€‚

Usage:
    python rest_client.py --host localhost --port 8501
"""

import argparse
import time
from typing import Dict, List, Tuple

import numpy as np
import requests


class IrisRESTClient:
    """TensorFlow Serving RESTã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self, host: str = "localhost", port: int = 8501, model_name: str = "iris"):
        """
        Args:
            host: TensorFlow Servingã®ãƒ›ã‚¹ãƒˆ
            port: RESTãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8501ï¼‰
            model_name: ãƒ¢ãƒ‡ãƒ«å
        """
        self.host = host
        self.port = port
        self.model_name = model_name
        self.base_url = f"http://{host}:{port}/v1/models/{model_name}"

    def get_model_status(self) -> Dict:
        """
        ãƒ¢ãƒ‡ãƒ«ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—ã™ã‚‹

        Returns:
            Dict: ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æƒ…å ±
        """
        url = self.base_url
        print(f"Getting model status from {url}...")

        try:
            response = requests.get(url, timeout=10.0)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ Error getting model status: {e}")
            raise

    def get_model_metadata(self) -> Dict:
        """
        ãƒ¢ãƒ‡ãƒ«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã™ã‚‹

        Returns:
            Dict: ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆå…¥å‡ºåŠ›ã®ã‚·ã‚°ãƒãƒãƒ£æƒ…å ±ï¼‰
        """
        url = f"{self.base_url}/metadata"
        print(f"Getting model metadata from {url}...")

        try:
            response = requests.get(url, timeout=10.0)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            print(f"âŒ Error getting model metadata: {e}")
            raise

    def predict(
        self,
        data: List[List[float]],
        timeout: float = 10.0,
    ) -> Tuple[np.ndarray, float]:
        """
        æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆinstanceså½¢å¼ï¼‰

        Args:
            data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ [[sepal_length, sepal_width, petal_length, petal_width], ...]
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

        Returns:
            Tuple[np.ndarray, float]: (æ¨è«–çµæœ, ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ )
        """
        url = f"{self.base_url}:predict"

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ï¼ˆinstanceså½¢å¼ï¼‰
        payload = {
            "instances": data
        }

        # æ¨è«–å®Ÿè¡Œï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ æ¸¬å®šï¼‰
        start_time = time.time()
        try:
            response = requests.post(url, json=payload, timeout=timeout)
            response_time = time.time() - start_time
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"âŒ HTTP Error: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"Response: {e.response.text}")
            raise

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ¨è«–çµæœã‚’å–å¾—
        result = response.json()
        predictions = np.array(result["predictions"])

        return predictions, response_time

    def predict_with_inputs(
        self,
        data: List[List[float]],
        timeout: float = 10.0,
    ) -> Tuple[np.ndarray, float]:
        """
        æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ï¼ˆinputså½¢å¼ï¼‰

        Args:
            data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

        Returns:
            Tuple[np.ndarray, float]: (æ¨è«–çµæœ, ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ )
        """
        url = f"{self.base_url}:predict"

        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ï¼ˆinputså½¢å¼ï¼‰
        payload = {
            "inputs": {
                "input": data
            }
        }

        # æ¨è«–å®Ÿè¡Œ
        start_time = time.time()
        try:
            response = requests.post(url, json=payload, timeout=timeout)
            response_time = time.time() - start_time
            response.raise_for_status()
        except requests.exceptions.RequestException as e:
            print(f"âŒ HTTP Error: {e}")
            if hasattr(e, 'response') and e.response is not None:
                print(f"Response: {e.response.text}")
            raise

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ¨è«–çµæœã‚’å–å¾—
        result = response.json()
        predictions = np.array(result["predictions"])

        return predictions, response_time

    def predict_class(
        self, data: List[List[float]], class_names: List[str] = None
    ) -> Tuple[List[str], float]:
        """
        æ¨è«–ã‚’å®Ÿè¡Œã—ã¦ã‚¯ãƒ©ã‚¹åã‚’è¿”ã™

        Args:
            data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
            class_names: ã‚¯ãƒ©ã‚¹åãƒªã‚¹ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ["setosa", "versicolor", "virginica"]ï¼‰

        Returns:
            Tuple[List[str], float]: (äºˆæ¸¬ã‚¯ãƒ©ã‚¹åã®ãƒªã‚¹ãƒˆ, ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ )
        """
        if class_names is None:
            class_names = ["setosa", "versicolor", "virginica"]

        # æ¨è«–å®Ÿè¡Œ
        probabilities, response_time = self.predict(data)

        # æœ€å¤§ç¢ºç‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        predicted_classes = []
        for prob in probabilities:
            class_idx = np.argmax(prob)
            predicted_classes.append(class_names[class_idx])

        return predicted_classes, response_time


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="TensorFlow Serving REST Client for Iris")
    parser.add_argument(
        "--host",
        type=str,
        default="localhost",
        help="TensorFlow Serving host (default: localhost)",
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8501,
        help="REST port (default: 8501)",
    )
    parser.add_argument(
        "--model-name",
        type=str,
        default="iris",
        help="Model name (default: iris)",
    )

    args = parser.parse_args()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆIris setosaã€versicolorã€virginica ã®ä»£è¡¨ä¾‹ï¼‰
    test_data = [
        [5.1, 3.5, 1.4, 0.2],  # setosa
        [6.3, 3.3, 4.7, 1.6],  # versicolor
        [6.3, 3.3, 6.0, 2.5],  # virginica
    ]

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = IrisRESTClient(host=args.host, port=args.port, model_name=args.model_name)

    try:
        print("\n========================================")
        print("ğŸ”® Iris Classification - REST Client")
        print("========================================\n")

        # 0. ãƒ¢ãƒ‡ãƒ«ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
        print("0ï¸âƒ£ Model Status:")
        status = client.get_model_status()
        print(f"  {status}\n")

        # 1. ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç¢ºèª
        print("1ï¸âƒ£ Model Metadata:")
        metadata = client.get_model_metadata()
        print(f"  Model: {metadata.get('model_spec', {}).get('name')}")
        print(f"  Version: {metadata.get('model_spec', {}).get('version')}\n")

        # 2. ç¢ºç‡å€¤ã§æ¨è«–ï¼ˆinstanceså½¢å¼ï¼‰
        print("2ï¸âƒ£ Prediction with probabilities (instances format):")
        probabilities, response_time = client.predict(test_data)

        for i, (data, prob) in enumerate(zip(test_data, probabilities)):
            print(f"\n  Sample {i+1}: {data}")
            print(f"    Probabilities: {prob}")
            print(f"    Predicted class: {np.argmax(prob)}")
            print(f"    Response time: {response_time*1000:.2f}ms")

        # 3. ç¢ºç‡å€¤ã§æ¨è«–ï¼ˆinputså½¢å¼ï¼‰
        print("\n3ï¸âƒ£ Prediction with probabilities (inputs format):")
        probabilities, response_time = client.predict_with_inputs(test_data)

        for i, (data, prob) in enumerate(zip(test_data, probabilities)):
            print(f"\n  Sample {i+1}: {data}")
            print(f"    Probabilities: {prob}")
            print(f"    Response time: {response_time*1000:.2f}ms")

        # 4. ã‚¯ãƒ©ã‚¹åã§æ¨è«–
        print("\n4ï¸âƒ£ Prediction with class names:")
        class_names, response_time = client.predict_class(test_data)

        for i, (data, class_name) in enumerate(zip(test_data, class_names)):
            print(f"\n  Sample {i+1}: {data}")
            print(f"    Predicted: {class_name}")
            print(f"    Response time: {response_time*1000:.2f}ms")

        print("\n========================================")
        print("âœ… REST Client Test Completed")
        print("========================================\n")

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        raise


if __name__ == "__main__":
    main()
