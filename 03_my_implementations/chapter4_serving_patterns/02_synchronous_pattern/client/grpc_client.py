#!/usr/bin/env python3
"""
gRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ

TensorFlow Servingã®gRPCã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦æ¨è«–ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚
gRPCã¯ãƒã‚¤ãƒŠãƒªãƒ—ãƒ­ãƒˆã‚³ãƒ«ã§RESTã‚ˆã‚Šé«˜é€Ÿã§ã™ã€‚

Usage:
    python grpc_client.py --host localhost --port 8500
"""

import argparse
import time
from typing import List, Tuple

import grpc
import numpy as np
from tensorflow_serving.apis import predict_pb2, prediction_service_pb2_grpc
import tensorflow as tf


class IrisGRPCClient:
    """TensorFlow Serving gRPCã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""

    def __init__(self, host: str = "localhost", port: int = 8500, model_name: str = "iris"):
        """
        Args:
            host: TensorFlow Servingã®ãƒ›ã‚¹ãƒˆ
            port: gRPCãƒãƒ¼ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 8500ï¼‰
            model_name: ãƒ¢ãƒ‡ãƒ«å
        """
        self.host = host
        self.port = port
        self.model_name = model_name
        self.server_url = f"{host}:{port}"
        self.channel = None
        self.stub = None

    def connect(self) -> None:
        """gRPCãƒãƒ£ãƒãƒ«ã‚’ç¢ºç«‹ã™ã‚‹"""
        print(f"Connecting to TensorFlow Serving at {self.server_url}...")
        self.channel = grpc.insecure_channel(self.server_url)
        self.stub = prediction_service_pb2_grpc.PredictionServiceStub(self.channel)
        print("âœ… Connected successfully")

    def close(self) -> None:
        """gRPCãƒãƒ£ãƒãƒ«ã‚’é–‰ã˜ã‚‹"""
        if self.channel:
            self.channel.close()
            print("Connection closed")

    def predict(
        self,
        data: List[List[float]],
        signature_name: str = "serving_default",
        timeout: float = 10.0,
    ) -> Tuple[np.ndarray, float]:
        """
        æ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹

        Args:
            data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ [[sepal_length, sepal_width, petal_length, petal_width], ...]
            signature_name: Serving signatureå
            timeout: ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆç§’ï¼‰

        Returns:
            Tuple[np.ndarray, float]: (æ¨è«–çµæœ, ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ )
        """
        if not self.stub:
            raise RuntimeError("Not connected. Call connect() first.")

        # PredictRequestã‚’ä½œæˆ
        request = predict_pb2.PredictRequest()
        request.model_spec.name = self.model_name
        request.model_spec.signature_name = signature_name

        # å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’TensorProtoã«å¤‰æ›
        input_data = np.array(data, dtype=np.float32)
        request.inputs["input"].CopyFrom(
            tf.make_tensor_proto(input_data, shape=input_data.shape)
        )

        # æ¨è«–å®Ÿè¡Œï¼ˆãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ æ¸¬å®šï¼‰
        start_time = time.time()
        try:
            response = self.stub.Predict(request, timeout=timeout)
            response_time = time.time() - start_time
        except grpc.RpcError as e:
            print(f"âŒ gRPC Error: {e.code()} - {e.details()}")
            raise

        # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰æ¨è«–çµæœã‚’å–å¾—
        output = tf.make_ndarray(response.outputs["output"])

        return output, response_time

    def predict_class(
        self, data: List[List[float]], class_names: List[str] = None
    ) -> Tuple[List[str], float]:
        """
        æ¨è«–ã‚’å®Ÿè¡Œã—ã¦ã‚¯ãƒ©ã‚¹åã‚’è¿”ã™

        Args:
            data: å…¥åŠ›ãƒ‡ãƒ¼ã‚¿
            class_names: ã‚¯ãƒ©ã‚¹åãƒªã‚¹ãƒˆï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ["setosa", "versicolor", "virginica"]ï¼‰

        Returns:
            Tuple[List[str], float]: (äºˆæ¸¬ã‚¯ãƒ©ã‚¹åã®ãƒªã‚¹ãƒˆ, ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚¿ã‚¤ãƒ )
        """
        if class_names is None:
            class_names = ["setosa", "versicolor", "virginica"]

        # æ¨è«–å®Ÿè¡Œ
        probabilities, response_time = self.predict(data)

        # æœ€å¤§ç¢ºç‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        predicted_classes = []
        for prob in probabilities:
            class_idx = np.argmax(prob)
            predicted_classes.append(class_names[class_idx])

        return predicted_classes, response_time


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    parser = argparse.ArgumentParser(description="TensorFlow Serving gRPC Client for Iris")
    parser.add_argument(
        "--host",
        type=str,
        default="localhost",
        help="TensorFlow Serving host (default: localhost)",
    )
    parser.add_argument(
        "--port",
        type=int,
        default=8500,
        help="gRPC port (default: 8500)",
    )
    parser.add_argument(
        "--model-name",
        type=str,
        default="iris",
        help="Model name (default: iris)",
    )

    args = parser.parse_args()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆIris setosaã€versicolorã€virginica ã®ä»£è¡¨ä¾‹ï¼‰
    test_data = [
        [5.1, 3.5, 1.4, 0.2],  # setosa
        [6.3, 3.3, 4.7, 1.6],  # versicolor
        [6.3, 3.3, 6.0, 2.5],  # virginica
    ]

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–
    client = IrisGRPCClient(host=args.host, port=args.port, model_name=args.model_name)

    try:
        # æ¥ç¶š
        client.connect()

        print("\n========================================")
        print("ğŸ”® Iris Classification - gRPC Client")
        print("========================================\n")

        # 1. ç¢ºç‡å€¤ã§æ¨è«–
        print("1ï¸âƒ£ Prediction with probabilities:")
        probabilities, response_time = client.predict(test_data)

        for i, (data, prob) in enumerate(zip(test_data, probabilities)):
            print(f"\n  Sample {i+1}: {data}")
            print(f"    Probabilities: {prob}")
            print(f"    Predicted class: {np.argmax(prob)}")
            print(f"    Response time: {response_time*1000:.2f}ms")

        # 2. ã‚¯ãƒ©ã‚¹åã§æ¨è«–
        print("\n2ï¸âƒ£ Prediction with class names:")
        class_names, response_time = client.predict_class(test_data)

        for i, (data, class_name) in enumerate(zip(test_data, class_names)):
            print(f"\n  Sample {i+1}: {data}")
            print(f"    Predicted: {class_name}")
            print(f"    Response time: {response_time*1000:.2f}ms")

        print("\n========================================")
        print("âœ… gRPC Client Test Completed")
        print("========================================\n")

    except Exception as e:
        print(f"\nâŒ Error: {e}")
        raise

    finally:
        # æ¥ç¶šã‚’é–‰ã˜ã‚‹
        client.close()


if __name__ == "__main__":
    main()
