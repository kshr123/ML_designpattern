# ================================================================================
# Dockerfile.worker - Worker Service（推論実行）のDockerイメージ
# ================================================================================
#
# 【このDockerfileの目的】
#   - Redisキューからジョブを取得し、推論を実行するWorkerを構築
#   - ONNX Runtimeで推論を実行
#   - 推論結果をRedisに保存
#
# 【Workerサービスの役割】
#   1. Redisキューからジョブを取得（BRPOP: ブロッキング方式）
#   2. 入力データをRedisから取得
#   3. ONNX Runtimeで推論実行
#   4. 推論結果をRedisに保存
#   5. ジョブステータスを更新（pending → processing → completed）
#
# 【なぜBRPOPを使うのか】
#   - ポーリング不要: キューにジョブが来るまでブロック（CPU効率的）
#   - 低レイテンシ: ジョブ到着時に即座に処理開始
#   - Redis負荷軽減: 無駄なクエリがない
#
# 【スケールアウト】
#   - docker-compose.ymlで replicas: 2 を設定
#   - 複数Workerが並列でジョブを処理
#   - BRPOPは先着順で1つのWorkerだけがジョブを取得（重複なし）
#
# ================================================================================

# ベースイメージ: Python 3.11 Slim
FROM python:3.11-slim

# 作業ディレクトリの設定
WORKDIR /app

# ================================================================================
# 依存関係のインストール
# ================================================================================
#
# 【インストールするパッケージ】
#   - redis: Redisクライアント（キュー操作、データ取得/保存）
#   - numpy: 数値計算ライブラリ（入力データの配列操作）
#   - onnxruntime: ONNX推論エンジン
#
# 【なぜONNX Runtimeを使うのか】
#   - クロスプラットフォーム対応（Apple Silicon含む）
#   - 軽量で高速な推論
#   - Pythonコードから直接実行可能（gRPC不要）
#   - Scikit-learn, PyTorchなどのモデルをONNX形式に変換して使用
#
COPY pyproject.toml ./

RUN pip install --no-cache-dir \
    redis \
    numpy \
    onnxruntime

# ================================================================================
# ONNXモデルのコピー
# ================================================================================
#
# models/: ONNX形式のモデルファイル
#   - iris_svc.onnx: Iris分類モデル（約1KB）
#   - このモデルはScikit-learnのSVCをONNX形式に変換したもの
#
# 【ONNXモデルの利点】
#   - フレームワーク非依存（Scikit-learn不要）
#   - 推論が高速（最適化済み）
#   - サイズが小さい（モデルのみ、学習ライブラリ不要）
#
COPY models/ ./models/

# ================================================================================
# ソースコードのコピー
# ================================================================================
#
# src/: Worker関連のPythonソースコード
#   - src/worker/: Workerサービスのロジック
#   - src/worker/worker.py: メインループ（BRPOP → 推論 → 保存）
#   - src/worker/predictor.py: ONNX Runtime推論ロジック
#   - src/worker/redis_client.py: Redis操作
#
# run_worker.sh: 起動スクリプト
#   - python -m src.worker.worker でWorkerを起動
#   - 無限ループでキューを監視
#
COPY src/ ./src/
COPY run_worker.sh ./

# ================================================================================
# 起動コマンド
# ================================================================================
#
# 【run_worker.sh】
#   - python -m src.worker.worker を実行
#   - 無限ループでBRPOPを実行
#   - ジョブが来たら推論実行
#
# 【処理フロー】
#   1. redis.brpop(queue_name, timeout=1)
#   2. job_idを取得
#   3. redis.get(f"job:{job_id}:data") でデータ取得
#   4. onnx_session.run() で推論実行
#   5. redis.set(f"job:{job_id}:result", result)
#   6. redis.set(f"job:{job_id}:status", "completed")
#
CMD ["./run_worker.sh"]
