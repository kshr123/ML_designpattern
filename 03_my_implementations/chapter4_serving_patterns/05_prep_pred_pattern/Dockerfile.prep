# ================================================================================
# Dockerfile.prep - 前処理サービス（Prep Service）のDockerイメージ
# ================================================================================
#
# 【このDockerfileの目的】
#   - Base64画像を受け取って前処理を行うFastAPIサービスを構築
#   - 前処理（リサイズ、正規化）と後処理（Softmax）のTransformerを事前準備
#   - gRPCクライアントとして推論サービス（Pred Service）と通信
#
# 【マルチステージビルドを使う理由】
#   - Stage 1: 重い依存関係を使ってTransformerを作成・保存（joblib pkl）
#   - Stage 2: 軽量なランタイムイメージに必要なファイルだけコピー
#   - 結果: 最終イメージサイズを小さくできる（不要なビルドツールを含まない）
#
# 【全体の流れ】
#   1. [Stage 1] Transformerを抽出してpklファイルに保存
#   2. [Stage 2] FastAPIアプリ + pklファイルで軽量な本番イメージを作成
#
# ================================================================================

# ================================================================================
# Stage 1: Transformer抽出ステージ（builder）
# ================================================================================
#
# 【目的】
#   - PytorchImagePreprocessTransformer（前処理）を作成
#   - SoftmaxTransformer（後処理）を作成
#   - 両方をjoblibでpklファイルに保存
#
# 【なぜこのステージが必要か】
#   - Transformerの作成には多くの依存パッケージが必要（numpy, scikit-learn等）
#   - 作成したpklファイルは小さい（数KB〜数MB）
#   - 最終イメージには作成済みpklだけあればよく、ビルド依存を含める必要がない
#
FROM python:3.11-slim as builder

# ビルド引数: ResNet50関連ファイルのディレクトリ
ARG SERVER_DIR=resnet50_onnx_runtime
ENV PROJECT_DIR=prep_pred_pattern

WORKDIR /${PROJECT_DIR}

# requirements.txtを先にコピー（Dockerキャッシュ活用のため）
# 理由: 依存関係は頻繁に変わらないので、キャッシュを効かせて高速化
ADD ./${SERVER_DIR}/requirements.txt /${PROJECT_DIR}/

# Transformer抽出に必要なファイルをコピー
# - extract_resnet50_onnx.py: Transformerを作成するスクリプト
# - transformers.py: Transformer実装
# - constants.py: 定数定義（画像サイズ、正規化パラメータ等）
# - cat.jpg: サンプル画像（Transformer動作確認用）
# - image_net_labels.json: ImageNet 1000クラスのラベル
COPY ./${SERVER_DIR}/extract_resnet50_onnx.py /${PROJECT_DIR}/extract_resnet50_onnx.py
COPY ./src/ml/transformers.py /${PROJECT_DIR}/src/ml/transformers.py
COPY ./src/constants.py /${PROJECT_DIR}/src/constants.py
COPY ./data/cat.jpg /${PROJECT_DIR}/data/cat.jpg
COPY ./data/image_net_labels.json /${PROJECT_DIR}/data/image_net_labels.json

# パッケージインストール & Transformer抽出の実行
RUN apt-get -y update && \
    # ビルドツールのインストール（一部パッケージのコンパイルに必要）
    apt-get -y install apt-utils gcc && \
    # キャッシュクリーンアップ（イメージサイズ削減）
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    # Python依存関係をインストール（numpy, scikit-learn, Pillow等）
    pip install --no-cache-dir -r requirements.txt && \
    # Pythonモジュールとして認識させるため__init__.pyを作成
    touch __init__.py && \
    touch src/__init__.py && \
    touch src/ml/__init__.py && \
    # Transformer抽出スクリプトを実行
    # --prep: 前処理・後処理Transformerのみ抽出（推論モデルは不要）
    # → models/preprocess_transformer.pkl
    # → models/softmax_transformer.pkl が生成される
    python -m extract_resnet50_onnx --prep

# ================================================================================
# Stage 2: 本番ランタイムイメージ
# ================================================================================
#
# 【目的】
#   - FastAPIアプリケーションを実行する軽量な本番イメージ
#   - Stage 1で作成したpklファイルを利用
#
# 【含まれるもの】
#   - FastAPIアプリケーション（src/app/）
#   - gRPCクライアント（src/ml/prediction.py）
#   - 事前作成済みTransformer（pklファイル）
#   - Protocol Buffers定義（src/proto/）
#
FROM python:3.11-slim

ENV PROJECT_DIR=prep_pred_pattern
# モデル（pklファイル）の保存先ベースパス
ENV MODEL_BASE_PATH=/${PROJECT_DIR}/models

WORKDIR /${PROJECT_DIR}

# requirements.txtをコピー（再度必要、Stage 1とは別イメージ）
ADD ./requirements.txt /${PROJECT_DIR}/

# ランタイムに必要な依存関係をインストール
RUN apt-get -y update && \
    apt-get -y install apt-utils gcc && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/* && \
    # FastAPI, gRPC, Pillow, numpy等をインストール
    pip install --no-cache-dir -r requirements.txt

# アプリケーションコード全体をコピー
# - src/app/: FastAPIルーター、エンドポイント定義
# - src/ml/: 推論ロジック、Transformer定義
# - src/proto/: Protocol Buffers（gRPC通信用）
# - src/configurations.py: 環境変数読み込み
# - src/constants.py: 定数定義
COPY ./src/ /${PROJECT_DIR}/src/

# 【重要】Stage 1で生成したTransformer（pklファイル）をコピー
# --from=builder: Stage 1（builder）から取得
# これらのpklファイルは起動時にjoblibでロードされる
COPY --from=builder /${MODEL_BASE_PATH}/preprocess_transformer.pkl ${MODEL_BASE_PATH}/preprocess_transformer.pkl
COPY --from=builder /${MODEL_BASE_PATH}/softmax_transformer.pkl ${MODEL_BASE_PATH}/softmax_transformer.pkl

# サンプルデータをコピー（/predict/test エンドポイントで使用）
COPY ./data/cat.jpg /${PROJECT_DIR}/data/cat.jpg
COPY ./data/image_net_labels.json /${PROJECT_DIR}/data/image_net_labels.json

# ================================================================================
# 環境変数の設定
# ================================================================================
# アプリケーション起動時にこれらの環境変数が読み込まれる
# （src/configurations.py で os.getenv() により取得）

# Transformerファイルのパス
ENV PREPROCESS_TRANSFORMER_PATH=${MODEL_BASE_PATH}/preprocess_transformer.pkl
ENV SOFTMAX_TRANSFORMER_PATH=${MODEL_BASE_PATH}/softmax_transformer.pkl

# サンプル画像とラベルのパス
ENV SAMPLE_IMAGE_PATH=/${PROJECT_DIR}/data/cat.jpg
ENV LABEL_PATH=/${PROJECT_DIR}/data/image_net_labels.json

# ログ設定
ENV LOG_LEVEL=INFO
ENV LOG_FORMAT=TEXT

# ================================================================================
# 起動スクリプトの準備
# ================================================================================
# run.sh: gunicornでFastAPIアプリを起動するスクリプト
# - 複数ワーカーでリクエストを並列処理
# - 本番環境に適した設定（リクエスト制限、グレースフルシャットダウン等）
COPY ./run.sh /${PROJECT_DIR}/run.sh
RUN chmod +x /${PROJECT_DIR}/run.sh

# コンテナ起動時に実行されるコマンド
# run.sh → gunicorn → FastAPIアプリ（src.app.app:app）を起動
CMD ["./run.sh"]
