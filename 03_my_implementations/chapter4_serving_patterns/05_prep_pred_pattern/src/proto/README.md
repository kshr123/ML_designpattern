# proto/ - Protocol Buffers ã¨ gRPCé€šä¿¡

## ğŸ“š ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¤ã„ã¦

ã“ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã¯ã€**Prep Serviceã¨Pred Serviceã®é–“ã®é€šä¿¡**ã‚’å®šç¾©ã™ã‚‹Protocol Buffersãƒ•ã‚¡ã‚¤ãƒ«ãŒå«ã¾ã‚Œã¦ã„ã¾ã™ã€‚

Protocol Buffersï¼ˆprotobufï¼‰ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ³ãƒ‘ã‚¯ãƒˆã«é€å—ä¿¡ã™ã‚‹ãŸã‚ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã§ã€gRPCé€šä¿¡ã§ä½¿ç”¨ã•ã‚Œã¾ã™ã€‚

## ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

```
proto/
â”œâ”€â”€ README.md                       # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”‚
â”œâ”€â”€ predict.proto                   # ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å®šç¾©
â”œâ”€â”€ prediction_service.proto        # gRPCã‚µãƒ¼ãƒ“ã‚¹ã®å®šç¾©
â”œâ”€â”€ onnx-ml.proto                   # ONNXãƒ‡ãƒ¼ã‚¿å‹ã®å®šç¾©
â”‚
â”œâ”€â”€ predict_pb2.py                  # predict.proto ã‹ã‚‰è‡ªå‹•ç”Ÿæˆ
â”œâ”€â”€ predict_pb2_grpc.py             # predict.proto ã®gRPCéƒ¨åˆ†
â”œâ”€â”€ prediction_service_pb2.py       # prediction_service.proto ã‹ã‚‰è‡ªå‹•ç”Ÿæˆ
â”œâ”€â”€ prediction_service_pb2_grpc.py  # prediction_service.proto ã®gRPCéƒ¨åˆ†
â”œâ”€â”€ onnx_ml_pb2.py                  # onnx-ml.proto ã‹ã‚‰è‡ªå‹•ç”Ÿæˆ
â””â”€â”€ onnx_ml_pb2_grpc.py             # onnx-ml.proto ã®gRPCéƒ¨åˆ†
```

**é‡è¦**: `*_pb2.py`ãƒ•ã‚¡ã‚¤ãƒ«ã¯è‡ªå‹•ç”Ÿæˆã•ã‚Œã‚‹ãŸã‚ã€ç›´æ¥ç·¨é›†ã—ãªã„ã§ãã ã•ã„ã€‚

## ğŸ”„ é€šä¿¡ãƒ•ãƒ­ãƒ¼å…¨ä½“å›³

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prep Service (prediction.py)                               â”‚
â”‚                                                              â”‚
â”‚  # 1. gRPCãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ                                    â”‚
â”‚  request = PredictRequest()                                 â”‚
â”‚  request.inputs["input"].dims = [1, 3, 224, 224]            â”‚
â”‚  request.inputs["input"].data_type = 1  # float32           â”‚
â”‚  request.inputs["input"].raw_data = image_bytes             â”‚
â”‚                                                              â”‚
â”‚  # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä¸­èº«ï¼ˆProtocol Bufferså½¢å¼ï¼‰                â”‚
â”‚  PredictRequest {                                           â”‚
â”‚    inputs: {                                                â”‚
â”‚      "input": TensorProto {                                 â”‚
â”‚        dims: [1, 3, 224, 224]                               â”‚
â”‚        data_type: FLOAT (1)                                 â”‚
â”‚        raw_data: <150,528ãƒã‚¤ãƒˆã®ãƒã‚¤ãƒŠãƒª>                  â”‚
â”‚      }                                                       â”‚
â”‚    }                                                         â”‚
â”‚  }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ gRPCé€šä¿¡ï¼ˆãƒã‚¤ãƒŠãƒªå½¢å¼ï¼‰
                         â”‚ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯: pred:50051
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Pred Service (ONNX Runtime Server)                         â”‚
â”‚                                                              â”‚
â”‚  # 2. ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å—ä¿¡ã—ã¦æ¨è«–                              â”‚
â”‚  def Predict(request):                                      â”‚
â”‚      inputs = request.inputs["input"]                       â”‚
â”‚      # ResNet50ãƒ¢ãƒ‡ãƒ«ã§æ¨è«–                                 â”‚
â”‚      outputs = model.run(inputs)                            â”‚
â”‚                                                              â”‚
â”‚      # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ                                       â”‚
â”‚      response = PredictResponse()                           â”‚
â”‚      response.outputs["output"].dims = [1, 1000]            â”‚
â”‚      response.outputs["output"].data_type = 1               â”‚
â”‚      response.outputs["output"].raw_data = outputs.tobytes()â”‚
â”‚      return response                                        â”‚
â”‚                                                              â”‚
â”‚  # ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä¸­èº«ï¼ˆProtocol Bufferså½¢å¼ï¼‰                â”‚
â”‚  PredictResponse {                                          â”‚
â”‚    outputs: {                                               â”‚
â”‚      "output": TensorProto {                                â”‚
â”‚        dims: [1, 1000]                                      â”‚
â”‚        data_type: FLOAT (1)                                 â”‚
â”‚        raw_data: <4,000ãƒã‚¤ãƒˆã®ãƒã‚¤ãƒŠãƒª>                    â”‚
â”‚      }                                                       â”‚
â”‚    }                                                         â”‚
â”‚  }                                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â”‚ gRPCé€šä¿¡ï¼ˆãƒã‚¤ãƒŠãƒªå½¢å¼ï¼‰
                         â”‚
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prep Service (prediction.py)                               â”‚
â”‚                                                              â”‚
â”‚  # 3. ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡                                      â”‚
â”‚  response = stub.Predict(request)                           â”‚
â”‚  output = np.frombuffer(                                    â”‚
â”‚      response.outputs["output"].raw_data,                   â”‚
â”‚      dtype=np.float32                                       â”‚
â”‚  )                                                           â”‚
â”‚  # â†’ (1000,) numpyé…åˆ—                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“„ predict.proto - ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹å®šç¾©

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ã€Œã©ã‚“ãªãƒ‡ãƒ¼ã‚¿ã‚’é€å—ä¿¡ã™ã‚‹ã‹ã€ã‚’å®šç¾©ã—ã¾ã™ã€‚

### ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹

```protobuf
syntax = "proto3";

import "onnx-ml.proto";

package onnxruntime.server;

// æ¨è«–ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
message PredictRequest {
  // å…¥åŠ›ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒãƒƒãƒ—
  // ã‚­ãƒ¼: ãƒ†ãƒ³ã‚½ãƒ«åï¼ˆä¾‹: "input"ï¼‰
  // å€¤: TensorProtoï¼ˆç”»åƒãƒ‡ãƒ¼ã‚¿ãªã©ï¼‰
  map<string, onnx.TensorProto> inputs = 2;

  // å‡ºåŠ›ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆçœç•¥å¯ï¼‰
  repeated string output_filter = 3;
}

// æ¨è«–ãƒ¬ã‚¹ãƒãƒ³ã‚¹
message PredictResponse {
  // å‡ºåŠ›ãƒ†ãƒ³ã‚½ãƒ«ã®ãƒãƒƒãƒ—
  // ã‚­ãƒ¼: ãƒ†ãƒ³ã‚½ãƒ«åï¼ˆä¾‹: "output"ï¼‰
  // å€¤: TensorProtoï¼ˆæ¨è«–çµæœï¼‰
  map<string, onnx.TensorProto> outputs = 1;
}
```

### é‡è¦ãªãƒã‚¤ãƒ³ãƒˆ: map ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰

`map<string, TensorProto>`ã¯ã€Pythonã®è¾æ›¸ã®ã‚ˆã†ã«ä½¿ãˆã¾ã™ï¼š

```python
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
request = PredictRequest()

# è¾æ›¸ã®ã‚ˆã†ã«å€¤ã‚’è¨­å®š
request.inputs["input"].dims.extend([1, 3, 224, 224])
request.inputs["input"].data_type = 1
request.inputs["input"].raw_data = image_bytes

# è¤‡æ•°ã®å…¥åŠ›ã‚‚å¯èƒ½
request.inputs["mask"].dims.extend([1, 1, 224, 224])
request.inputs["labels"].data = label_data
```

### ãªãœmapã‚’ä½¿ã†ã®ï¼Ÿ

```python
# mapã‚’ä½¿ã‚ãªã„å ´åˆï¼ˆé…åˆ—ï¼‰
request.inputs[0]  # ã“ã‚Œã¯ä½•ã®ãƒ‡ãƒ¼ã‚¿ï¼Ÿåˆ†ã‹ã‚‰ãªã„...
request.inputs[1]  # ã“ã‚Œã‚‚åˆ†ã‹ã‚‰ãªã„...

# mapã‚’ä½¿ã†å ´åˆ
request.inputs["input"]      # ç”»åƒãƒ‡ãƒ¼ã‚¿
request.inputs["mask"]       # ãƒã‚¹ã‚¯ãƒ‡ãƒ¼ã‚¿
request.inputs["metadata"]   # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
# â†’ åå‰ã§è­˜åˆ¥ã§ãã‚‹ï¼
```

## ğŸ“„ prediction_service.proto - gRPCã‚µãƒ¼ãƒ“ã‚¹å®šç¾©

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ã€Œã©ã‚“ãªãƒ¡ã‚½ãƒƒãƒ‰ãŒå‘¼ã³å‡ºã›ã‚‹ã‹ã€ã‚’å®šç¾©ã—ã¾ã™ã€‚

### ãƒ•ã‚¡ã‚¤ãƒ«å†…å®¹

```protobuf
syntax = "proto3";

import "predict.proto";

package onnxruntime.server;

// æ¨è«–ã‚µãƒ¼ãƒ“ã‚¹
service PredictionService {
  // æ¨è«–ãƒ¡ã‚½ãƒƒãƒ‰
  rpc Predict(PredictRequest) returns (PredictResponse);
}
```

### ä½¿ã„æ–¹ï¼ˆPythonã‚³ãƒ¼ãƒ‰ï¼‰

```python
import grpc
from src.proto import predict_pb2, prediction_service_pb2_grpc

# 1. gRPCæ¥ç¶šã‚’ç¢ºç«‹
channel = grpc.insecure_channel("pred:50051")

# 2. ã‚¹ã‚¿ãƒ–ï¼ˆãƒªãƒ¢ã‚³ãƒ³ï¼‰ã‚’ä½œæˆ
stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)

# 3. ãƒªã‚¯ã‚¨ã‚¹ãƒˆä½œæˆ
request = predict_pb2.PredictRequest()
request.inputs["input"].dims.extend([1, 3, 224, 224])
request.inputs["input"].raw_data = image_bytes

# 4. Predict ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å‘¼ã³å‡ºã—
response = stub.Predict(request)
# â†‘ ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é€šä¿¡ãŒç™ºç”Ÿï¼

# 5. ãƒ¬ã‚¹ãƒãƒ³ã‚¹å–å¾—
output = response.outputs["output"].raw_data
```

## ğŸ“„ onnx-ml.proto - ONNXãƒ‡ãƒ¼ã‚¿å‹å®šç¾©

ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€ONNX Runtime Serverã§ä½¿ã†ãƒ‡ãƒ¼ã‚¿å‹ã‚’å®šç¾©ã—ã¾ã™ï¼ˆONNXã®æ¨™æº–å®šç¾©ï¼‰ã€‚

### ä¸»è¦ãªå‹: TensorProto

```protobuf
message TensorProto {
  // ãƒ†ãƒ³ã‚½ãƒ«ã®æ¬¡å…ƒ
  // ä¾‹: [1, 3, 224, 224]
  repeated int64 dims = 1;

  // ãƒ‡ãƒ¼ã‚¿å‹
  // 1 = FLOAT, 2 = UINT8, 3 = INT8, ãªã©
  int32 data_type = 2;

  // ç”Ÿãƒ‡ãƒ¼ã‚¿ï¼ˆãƒã‚¤ãƒŠãƒªå½¢å¼ï¼‰
  bytes raw_data = 9;

  // ãã®ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰...
}
```

### Pythonã§ã®ä½¿ã„æ–¹

```python
from src.proto import onnx_ml_pb2

# TensorProtoä½œæˆ
tensor = onnx_ml_pb2.TensorProto()

# æ¬¡å…ƒã‚’è¨­å®š
tensor.dims.extend([1, 3, 224, 224])
# ã¾ãŸã¯
# tensor.dims.append(1)
# tensor.dims.append(3)
# tensor.dims.append(224)
# tensor.dims.append(224)

# ãƒ‡ãƒ¼ã‚¿å‹ã‚’è¨­å®š
tensor.data_type = 1  # FLOAT

# ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
import numpy as np
array = np.random.rand(1, 3, 224, 224).astype(np.float32)
tensor.raw_data = array.tobytes()

# ã‚µã‚¤ã‚ºç¢ºèª
print(len(tensor.raw_data))  # 150,528 bytes
# = 1 * 3 * 224 * 224 * 4 bytes (float32)
```

## ğŸ”§ Protocol Buffersãƒ•ã‚¡ã‚¤ãƒ«ã®å†ç”Ÿæˆ

`.proto`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å¤‰æ›´ã—ãŸã‚‰ã€Pythonã‚³ãƒ¼ãƒ‰ã‚’å†ç”Ÿæˆã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### æ‰‹é †

```bash
# 1. ä¸€æ™‚çš„ãªä»®æƒ³ç’°å¢ƒã‚’ä½œæˆï¼ˆprotobuf 4.25.3äº’æ›ï¼‰
python3 -m venv .venv_temp
source .venv_temp/bin/activate

# 2. grpcio-toolsã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install grpcio==1.60.0 grpcio-tools==1.60.0 protobuf==4.25.3

# 3. src/protoãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•
cd src/proto

# 4. protoãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
python -m grpc_tools.protoc \
  -I. \
  --python_out=. \
  --grpc_python_out=. \
  predict.proto prediction_service.proto onnx-ml.proto

# 5. ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ–‡ã‚’ä¿®æ­£ï¼ˆæ‰‹å‹•ï¼‰
# ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã® import æ–‡ã‚’ä¿®æ­£:
# 'import onnx_ml_pb2' â†’ 'from src.proto import onnx_ml_pb2'
# 'import predict_pb2' â†’ 'from src.proto import predict_pb2'

# 6. ä¸€æ™‚ç’°å¢ƒã‚’å‰Šé™¤
deactivate
cd ../..
rm -rf .venv_temp
```

### ãªãœæ‰‹å‹•ä¿®æ­£ãŒå¿…è¦ï¼Ÿ

`protoc`ã¯ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ãŒã€Pythonãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯çµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒå¿…è¦ã§ã™ï¼š

```python
# protocãŒç”Ÿæˆã™ã‚‹ã‚³ãƒ¼ãƒ‰ï¼ˆç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
import onnx_ml_pb2 as onnx__ml__pb2
# â†’ ModuleNotFoundError!

# ä¿®æ­£å¾Œï¼ˆçµ¶å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼‰
from src.proto import onnx_ml_pb2 as onnx__ml__pb2
# â†’ OK!
```

## ğŸ”‘ é‡è¦ãªæ¦‚å¿µ

### Protocol Buffers vs JSON

| ç‰¹å¾´ | JSON | Protocol Buffers |
|------|------|------------------|
| **å¯èª­æ€§** | â—‹ äººé–“ãŒèª­ã‚ã‚‹ | Ã— ãƒã‚¤ãƒŠãƒªã§èª­ã‚ãªã„ |
| **ã‚µã‚¤ã‚º** | å¤§ãã„ | å°ã•ã„ï¼ˆç´„1/3ï¼‰ |
| **é€Ÿåº¦** | é…ã„ | é€Ÿã„ï¼ˆç´„5å€ï¼‰ |
| **å‹å®‰å…¨æ€§** | Ã— ã‚†ã‚‹ã„ | â—‹ å³æ ¼ |
| **ã‚¹ã‚­ãƒ¼ãƒ** | ãªã— | .proto ãƒ•ã‚¡ã‚¤ãƒ«ã§å®šç¾© |

**ä¾‹: åŒã˜ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºæ¯”è¼ƒ**

```json
// JSON: ç´„500ãƒã‚¤ãƒˆ
{
  "inputs": {
    "input": {
      "dims": [1, 3, 224, 224],
      "dataType": 1,
      "rawData": "base64encodeddata..."
    }
  }
}
```

```python
# Protocol Buffers: ç´„150ãƒã‚¤ãƒˆ
request.inputs["input"].dims = [1, 3, 224, 224]
request.inputs["input"].data_type = 1
request.inputs["input"].raw_data = image_bytes
# â†’ ãƒã‚¤ãƒŠãƒªå½¢å¼ã§ç´„1/3ã®ã‚µã‚¤ã‚º
```

### gRPC vs REST API

| ç‰¹å¾´ | REST API | gRPC |
|------|----------|------|
| **ãƒ—ãƒ­ãƒˆã‚³ãƒ«** | HTTP/1.1 | HTTP/2 |
| **ãƒ‡ãƒ¼ã‚¿å½¢å¼** | JSONï¼ˆãƒ†ã‚­ã‚¹ãƒˆï¼‰ | Protocol Buffersï¼ˆãƒã‚¤ãƒŠãƒªï¼‰ |
| **é€Ÿåº¦** | é…ã„ | é€Ÿã„ |
| **ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°** | Ã— é›£ã—ã„ | â—‹ ç°¡å˜ |
| **ãƒ–ãƒ©ã‚¦ã‚¶ã‚µãƒãƒ¼ãƒˆ** | â—‹ ã™ã¹ã¦ã®ãƒ–ãƒ©ã‚¦ã‚¶ | â–³ é™å®šçš„ |

**ã‚³ãƒ¼ãƒ‰æ¯”è¼ƒ**

```python
# REST APIï¼ˆHTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰
import requests

response = requests.post(
    "http://pred:8001/predict",
    json={"inputs": {"input": {"dims": [1,3,224,224], ...}}}
)
output = response.json()["outputs"]["output"]

# gRPC
import grpc

channel = grpc.insecure_channel("pred:50051")
stub = PredictionServiceStub(channel)

request = PredictRequest()
request.inputs["input"].dims.extend([1, 3, 224, 224])

response = stub.Predict(request)
output = response.outputs["output"]
# â†’ ç´„3å€é€Ÿã„ï¼
```

## ğŸ› ï¸ ãƒ‡ãƒãƒƒã‚°ã®ãƒ’ãƒ³ãƒˆ

### ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ä¸­èº«ã‚’ç¢ºèª

```python
# ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å†…å®¹ã‚’è¡¨ç¤º
print(request)
# PredictRequest {
#   inputs: {
#     "input": TensorProto {
#       dims: [1, 3, 224, 224]
#       data_type: 1
#       raw_data: "<150528 bytes>"
#     }
#   }
# }

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®å†…å®¹ã‚’è¡¨ç¤º
print(response)
# PredictResponse {
#   outputs: {
#     "output": TensorProto {
#       dims: [1, 1000]
#       data_type: 1
#       raw_data: "<4000 bytes>"
#     }
#   }
# }
```

### ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚ºç¢ºèª

```python
# é€ä¿¡ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚º
print(f"Request size: {len(request.SerializeToString())} bytes")

# å—ä¿¡ãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚º
print(f"Response size: {len(response.SerializeToString())} bytes")

# ç”Ÿãƒ‡ãƒ¼ã‚¿ã®ã‚µã‚¤ã‚º
print(f"Raw data size: {len(request.inputs['input'].raw_data)} bytes")
# 1 * 3 * 224 * 224 * 4 = 150,528 bytes
```

### gRPCæ¥ç¶šã‚¨ãƒ©ãƒ¼ã®ãƒ‡ãƒãƒƒã‚°

```python
import grpc

try:
    channel = grpc.insecure_channel("pred:50051")
    stub = PredictionServiceStub(channel)
    response = stub.Predict(request, timeout=10)  # 10ç§’ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
except grpc.RpcError as e:
    print(f"gRPC error: {e.code()}")  # UNAVAILABLE, DEADLINE_EXCEEDED, ãªã©
    print(f"Details: {e.details()}")
```

## ğŸ¯ ã¾ã¨ã‚

`proto/`ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¯ã€Prep Serviceã¨Pred Serviceã®é€šä¿¡ãƒ—ãƒ­ãƒˆã‚³ãƒ«ã‚’å®šç¾©ã—ã¾ã™ï¼š

- **predict.proto**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
- **prediction_service.proto**: gRPCã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ¡ã‚½ãƒƒãƒ‰å®šç¾©
- **onnx-ml.proto**: ONNXãƒ‡ãƒ¼ã‚¿å‹ã®å®šç¾©

Protocol Buffersã‚’ä½¿ã†ã“ã¨ã§ã€**JSONã‚ˆã‚Šå°ã•ãé€Ÿã„ãƒ‡ãƒ¼ã‚¿é€šä¿¡**ãŒå®Ÿç¾ã§ãã¾ã™ã€‚

ã“ã‚Œã«ã‚ˆã‚Šã€æ©Ÿæ¢°å­¦ç¿’ã®æ¨è«–ã®ã‚ˆã†ãªå¤§é‡ãƒ‡ãƒ¼ã‚¿ã®ã‚„ã‚Šå–ã‚Šã§ã‚‚ã€åŠ¹ç‡çš„ãªé€šä¿¡ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚
