# One-Class SVMã¨å¤–ã‚Œå€¤æ¤œå‡ºæ‰‹æ³•

**ä½œæˆæ—¥**: 2025-11-05
**é–¢é€£å®Ÿè£…**: 05_iris_sklearn_outlier

---

## ğŸ“š ç›®æ¬¡

1. [One-Class SVMã¨ã¯](#one-class-svmã¨ã¯)
2. [ä»–ã®å¤–ã‚Œå€¤æ¤œå‡ºæ‰‹æ³•](#ä»–ã®å¤–ã‚Œå€¤æ¤œå‡ºæ‰‹æ³•)
3. [æ‰‹æ³•é¸æŠã‚¬ã‚¤ãƒ‰](#æ‰‹æ³•é¸æŠã‚¬ã‚¤ãƒ‰)
4. [å®Ÿè£…ä¾‹](#å®Ÿè£…ä¾‹)
5. [ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹](#ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹)

---

## One-Class SVMã¨ã¯

### åŸºæœ¬æ¦‚å¿µ

**One-Class SVMï¼ˆOne-Class Support Vector Machineï¼‰** ã¯ã€**æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿**ã‹ã‚‰å­¦ç¿’ã—ã€ç•°å¸¸ã‚„å¤–ã‚Œå€¤ã‚’æ¤œå‡ºã™ã‚‹æ•™å¸«ãªã—å­¦ç¿’ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã€‚

### ä¸»ãªç‰¹å¾´

#### 1. æ•™å¸«ãªã—å­¦ç¿’
- ãƒ©ãƒ™ãƒ«ï¼ˆæ­£å¸¸/ç•°å¸¸ï¼‰ãŒä¸è¦
- æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã ã‘ã§å­¦ç¿’å¯èƒ½
- ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã®åé›†ãŒå›°é›£ãªå ´åˆã«æœ‰åŠ¹

#### 2. æ±ºå®šå¢ƒç•Œã®å­¦ç¿’

```
æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®åˆ†å¸ƒ
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  â—  â—  â—       â”‚
    â”‚   â—  â—  â—      â”‚ â† æ±ºå®šå¢ƒç•Œï¼ˆè¶…å¹³é¢ï¼‰
    â”‚  â—  â—  â—       â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
    å¢ƒç•Œå¤– = å¤–ã‚Œå€¤
```

#### 3. ã‚«ãƒ¼ãƒãƒ«ãƒˆãƒªãƒƒã‚¯
- éç·šå½¢ãªå¢ƒç•Œã‚’å­¦ç¿’å¯èƒ½
- RBFã€linearã€polyã€sigmoidã‚«ãƒ¼ãƒãƒ«ãŒåˆ©ç”¨å¯èƒ½

#### 4. nuãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚ˆã‚‹åˆ¶å¾¡

```python
# nu = å¤–ã‚Œå€¤ã®ä¸Šé™å‰²åˆ
OneClassSVM(nu=0.1)  # æœ€å¤§10%ã‚’å¤–ã‚Œå€¤ã¨ã—ã¦è¨±å®¹
OneClassSVM(nu=0.05) # æœ€å¤§5%ã‚’å¤–ã‚Œå€¤ã¨ã—ã¦è¨±å®¹
```

### æ•°å­¦çš„ä»•çµ„ã¿

1. **åŸç‚¹ã‹ã‚‰ã®è·é›¢ã‚’æœ€å¤§åŒ–**
   - æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’åŸç‚¹ã‹ã‚‰æœ€ã‚‚é ã„è¶…å¹³é¢ã§åˆ†é›¢
   - å¢ƒç•Œå†…ãŒã€Œæ­£å¸¸ã€ã€å¢ƒç•Œå¤–ãŒã€Œç•°å¸¸ã€

2. **æ±ºå®šé–¢æ•°**
   ```
   f(x) = wÂ·Ï†(x) - Ï

   f(x) > 0  â†’ æ­£å¸¸ï¼ˆ+1ï¼‰
   f(x) < 0  â†’ ç•°å¸¸ï¼ˆ-1ï¼‰
   ```

3. **ã‚µãƒãƒ¼ãƒˆãƒ™ã‚¯ã‚¿ãƒ¼**
   - æ±ºå®šå¢ƒç•Œä¸Šã«ã‚ã‚‹ã‚µãƒ³ãƒ—ãƒ«
   - ãƒ¢ãƒ‡ãƒ«ã®è¤‡é›‘ã•ã‚’æ±ºå®š

### å®Ÿè£…ä¾‹ï¼ˆscikit-learnï¼‰

```python
from sklearn.svm import OneClassSVM
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æ§‹ç¯‰
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("ocs", OneClassSVM(nu=0.1, gamma="auto", kernel="rbf"))
])

# å­¦ç¿’ï¼ˆæ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ï¼‰
pipeline.fit(X_train)

# äºˆæ¸¬
predictions = pipeline.predict(X_test)  # +1: æ­£å¸¸, -1: ç•°å¸¸

# ç•°å¸¸ã‚¹ã‚³ã‚¢ï¼ˆæ±ºå®šé–¢æ•°å€¤ï¼‰
scores = pipeline.decision_function(X_test)  # è² ã®å€¤ã»ã©ç•°å¸¸
```

---

## ä»–ã®å¤–ã‚Œå€¤æ¤œå‡ºæ‰‹æ³•

### 1. Isolation Forest

**ç‰¹å¾´**:
- ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®æ‰‹æ³•
- ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã¯ã€Œå­¤ç«‹ã—ã‚„ã™ã„ã€ã¨ã„ã†æ€§è³ªã‚’åˆ©ç”¨

**ä»•çµ„ã¿**:
- ãƒ©ãƒ³ãƒ€ãƒ ã«ç‰¹å¾´é‡ã‚’é¸æŠ
- ãƒ©ãƒ³ãƒ€ãƒ ã«åˆ†å‰²ç‚¹ã‚’é¸æŠ
- å­¤ç«‹ã™ã‚‹ã¾ã§ã®åˆ†å‰²å›æ•°ãŒå°‘ãªã„ â†’ ç•°å¸¸

**å®Ÿè£…**:
```python
from sklearn.ensemble import IsolationForest

clf = IsolationForest(
    contamination=0.1,  # å¤–ã‚Œå€¤ã®å‰²åˆ
    random_state=42,
    n_estimators=100
)
clf.fit(X)
predictions = clf.predict(X)  # +1: æ­£å¸¸, -1: ç•°å¸¸
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- é«˜é€Ÿï¼ˆO(n log n)ï¼‰
- é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã«å¼·ã„
- ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒç°¡å˜

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- ãƒ©ãƒ³ãƒ€ãƒ æ€§ãŒé«˜ã„
- è§£é‡ˆæ€§ãŒä½ã„
- ç²¾åº¦ãŒOne-Class SVMã‚ˆã‚ŠåŠ£ã‚‹å ´åˆãŒã‚ã‚‹

**One-Class SVMã¨ã®æ¯”è¼ƒ**:

| é …ç›® | One-Class SVM | Isolation Forest |
|------|---------------|------------------|
| é€Ÿåº¦ | é…ã„ï¼ˆO(nÂ²)ï¼‰ | é€Ÿã„ï¼ˆO(n log n)ï¼‰|
| ç²¾åº¦ | é«˜ã„ | ã‚„ã‚„ä½ã„ |
| é«˜æ¬¡å…ƒ | è‹¦æ‰‹ | å¾—æ„ |
| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ | é›£ã—ã„ï¼ˆnu, gammaï¼‰ | ç°¡å˜ï¼ˆcontaminationï¼‰ |
| æ–°ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ | å¯èƒ½ | å¯èƒ½ |
| è§£é‡ˆæ€§ | ä¸­ | ä½ |

---

### 2. Local Outlier Factor (LOF)

**ç‰¹å¾´**:
- å±€æ‰€çš„ãªå¯†åº¦ã«åŸºã¥ãç•°å¸¸æ¤œçŸ¥
- kè¿‘å‚æ³•ãƒ™ãƒ¼ã‚¹

**ä»•çµ„ã¿**:
- å„ç‚¹ã®å‘¨è¾ºå¯†åº¦ã‚’è¨ˆç®—
- å‘¨è¾ºã®ç‚¹ã¨æ¯”è¼ƒã—ã¦å¯†åº¦ãŒä½ã„ â†’ ç•°å¸¸

**å®Ÿè£…**:
```python
from sklearn.neighbors import LocalOutlierFactor

lof = LocalOutlierFactor(
    n_neighbors=20,      # è¿‘å‚æ•°
    contamination=0.1,   # å¤–ã‚Œå€¤ã®å‰²åˆ
    novelty=True         # æ–°ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ã‚’æœ‰åŠ¹åŒ–
)
lof.fit(X_train)
predictions = lof.predict(X_test)  # +1: æ­£å¸¸, -1: ç•°å¸¸
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- å±€æ‰€çš„ãªç•°å¸¸ã‚’æ¤œå‡ºå¯èƒ½
- å¯†åº¦ã®ç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã«ã‚‚å¯¾å¿œ
- è§£é‡ˆæ€§ãŒé«˜ã„

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆn_neighborsï¼‰ã®é¸æŠãŒé›£ã—ã„
- å¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã§ã¯é…ã„
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯æ–°ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ä¸å¯ï¼ˆnovelty=Trueå¿…è¦ï¼‰

**One-Class SVMã¨ã®æ¯”è¼ƒ**:

| é …ç›® | One-Class SVM | LOF |
|------|---------------|-----|
| ç•°å¸¸ã®ç¨®é¡ | ã‚°ãƒ­ãƒ¼ãƒãƒ« | å±€æ‰€çš„ |
| æ–°ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ | å¯èƒ½ | novelty=Trueã§å¯èƒ½ |
| è§£é‡ˆæ€§ | ä¸­ | é«˜ã„ |
| é€Ÿåº¦ | ä¸­ | é…ã„ |

---

### 3. Autoencoderï¼ˆæ·±å±¤å­¦ç¿’ï¼‰

**ç‰¹å¾´**:
- ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã§æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®å†æ§‹æˆã‚’å­¦ç¿’
- å†æ§‹æˆèª¤å·®ãŒå¤§ãã„ = ç•°å¸¸

**ä»•çµ„ã¿**:
```
å…¥åŠ› â†’ Encoder â†’ Bottleneck â†’ Decoder â†’ å‡ºåŠ›
  X  â†’   åœ§ç¸®   â†’   æ½œåœ¨è¡¨ç¾  â†’  å¾©å…ƒ   â†’  X'

å†æ§‹æˆèª¤å·® = ||X - X'||Â²
```

**å®Ÿè£…**:
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

# Encoder-Decoder
model = Sequential([
    Dense(10, activation='relu', input_dim=4),  # Encoder
    Dense(2, activation='relu'),                # Bottleneck
    Dense(10, activation='relu'),               # Decoder
    Dense(4, activation='linear')               # Output
])

model.compile(optimizer='adam', loss='mse')
model.fit(X_train, X_train, epochs=50)  # è‡ªåˆ†è‡ªèº«ã‚’å†æ§‹æˆ

# ç•°å¸¸æ¤œçŸ¥
reconstructed = model.predict(X_test)
mse = np.mean((X_test - reconstructed)**2, axis=1)
threshold = np.percentile(mse, 95)
anomalies = mse > threshold
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- è¤‡é›‘ãªéç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’å¯èƒ½
- é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã«å¼·ã„
- ç”»åƒãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ»æ™‚ç³»åˆ—ã«ã‚‚å¯¾å¿œ
- æŸ”è»Ÿãªã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- å¤§é‡ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
- å­¦ç¿’ã«æ™‚é–“ãŒã‹ã‹ã‚‹
- ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå¤šã„
- éå­¦ç¿’ã—ã‚„ã™ã„

---

### 4. çµ±è¨ˆçš„æ‰‹æ³•

#### 4.1 Gaussian Distributionï¼ˆã‚¬ã‚¦ã‚¹åˆ†å¸ƒï¼‰

**ä»•çµ„ã¿**:
```python
from scipy import stats

# æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ãŒæ­£è¦åˆ†å¸ƒã«å¾“ã†ã¨ä»®å®š
mean = np.mean(X, axis=0)
cov = np.cov(X.T)

# ãƒãƒãƒ©ãƒãƒ“ã‚¹è·é›¢ã§ç•°å¸¸æ¤œçŸ¥
distances = [stats.mahalanobis(x, mean, np.linalg.inv(cov)) for x in X]
threshold = np.percentile(distances, 95)
anomalies = distances > threshold
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ã‚·ãƒ³ãƒ—ãƒ«ã§è§£é‡ˆã—ã‚„ã™ã„
- é«˜é€Ÿ
- ç†è«–çš„èƒŒæ™¯ãŒæ˜ç¢º

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- æ­£è¦åˆ†å¸ƒã®ä»®å®šãŒå¿…è¦
- å¤šå³°æ€§åˆ†å¸ƒã«å¼±ã„
- éç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œã§ããªã„

#### 4.2 PCAï¼ˆä¸»æˆåˆ†åˆ†æï¼‰ãƒ™ãƒ¼ã‚¹

**ä»•çµ„ã¿**:
```python
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca.fit(X)
X_reconstructed = pca.inverse_transform(pca.transform(X))

# å†æ§‹æˆèª¤å·®
reconstruction_error = np.sum((X - X_reconstructed)**2, axis=1)
threshold = np.percentile(reconstruction_error, 95)
anomalies = reconstruction_error > threshold
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- æ¬¡å…ƒå‰Šæ¸›ã¨ç•°å¸¸æ¤œçŸ¥ã‚’åŒæ™‚å®Ÿè¡Œ
- è¨ˆç®—ãŒé«˜é€Ÿ
- ãƒã‚¤ã‚ºé™¤å»åŠ¹æœ

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- ç·šå½¢å¤‰æ›ã®ã¿
- ä¸»æˆåˆ†æ•°ã®é¸æŠãŒé‡è¦
- éç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œã§ããªã„

---

### 5. DBSCANï¼ˆå¯†åº¦ãƒ™ãƒ¼ã‚¹ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼‰

**ä»•çµ„ã¿**:
```python
from sklearn.cluster import DBSCAN

dbscan = DBSCAN(
    eps=0.5,         # è¿‘å‚åŠå¾„
    min_samples=5    # æœ€å°ã‚µãƒ³ãƒ—ãƒ«æ•°
)
labels = dbscan.fit_predict(X)

# -1 = ãƒã‚¤ã‚ºï¼ˆå¤–ã‚Œå€¤ï¼‰
anomalies = labels == -1
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- ã‚¯ãƒ©ã‚¹ã‚¿æ•°ã‚’äº‹å‰æŒ‡å®šä¸è¦
- ä»»æ„ã®å½¢çŠ¶ã®ã‚¯ãƒ©ã‚¹ã‚¿ã‚’æ¤œå‡º
- ãƒã‚¤ã‚ºã‚’æ˜ç¤ºçš„ã«è­˜åˆ¥

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆeps, min_samplesï¼‰ã®é¸æŠãŒé›£ã—ã„
- å¯†åº¦ãŒç•°ãªã‚‹ã‚¯ãƒ©ã‚¹ã‚¿ã«å¼±ã„
- é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã§ã¯æ€§èƒ½ä½ä¸‹

---

## æ‰‹æ³•é¸æŠã‚¬ã‚¤ãƒ‰

### ãƒ‡ãƒ¼ã‚¿é‡ã§é¸ã¶

| ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º | æ¨å¥¨æ‰‹æ³• | ç†ç”± |
|------------|---------|------|
| å°ï¼ˆ< 1,000ï¼‰ | One-Class SVM, LOF | ç²¾åº¦é‡è¦– |
| ä¸­ï¼ˆ1,000-10,000ï¼‰ | Isolation Forest, One-Class SVM | ãƒãƒ©ãƒ³ã‚¹ |
| å¤§ï¼ˆ> 10,000ï¼‰ | Isolation Forest, Autoencoder | é€Ÿåº¦é‡è¦– |
| è¶…å¤§è¦æ¨¡ï¼ˆ> 100ä¸‡ï¼‰ | Isolation Forest, MiniBatchæ‰‹æ³• | ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£ |

### ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã§é¸ã¶

| ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ | æ¨å¥¨æ‰‹æ³• | ç†ç”± |
|-----------|---------|------|
| ä½æ¬¡å…ƒï¼ˆ< 10ï¼‰ | One-Class SVM, LOF | ã‚«ãƒ¼ãƒãƒ«ãƒ»å¯†åº¦ãƒ™ãƒ¼ã‚¹ãŒæœ‰åŠ¹ |
| ä¸­æ¬¡å…ƒï¼ˆ10-100ï¼‰ | Isolation Forest, PCA | ãƒãƒ©ãƒ³ã‚¹ãŒè‰¯ã„ |
| é«˜æ¬¡å…ƒï¼ˆ> 100ï¼‰ | Isolation Forest, Autoencoder, PCA | æ¬¡å…ƒã®å‘ªã„ã«å¼·ã„ |
| ç”»åƒ | Autoencoderï¼ˆCNNï¼‰ | ç©ºé–“æ§‹é€ ã‚’ä¿æŒ |
| ãƒ†ã‚­ã‚¹ãƒˆ | Autoencoderï¼ˆRNN/Transformerï¼‰ | ã‚·ãƒ¼ã‚±ãƒ³ã‚¹æ§‹é€  |
| æ™‚ç³»åˆ— | Autoencoderï¼ˆLSTMï¼‰, çµ±è¨ˆçš„æ‰‹æ³• | æ™‚é–“ä¾å­˜æ€§ |
| éç·šå½¢ | One-Class SVMï¼ˆRBFï¼‰, Autoencoder | è¤‡é›‘ãªå¢ƒç•Œ |
| ç·šå½¢ | PCA, One-Class SVMï¼ˆlinearï¼‰ | ã‚·ãƒ³ãƒ—ãƒ« |

### è¦ä»¶ã§é¸ã¶

| è¦ä»¶ | æ¨å¥¨æ‰‹æ³• | ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ• |
|-----|---------|------------|
| é«˜ç²¾åº¦ | One-Class SVM, Autoencoder | é€Ÿåº¦ãƒ»è¤‡é›‘ã• |
| é«˜é€Ÿ | Isolation Forest, çµ±è¨ˆçš„æ‰‹æ³• | ç²¾åº¦ |
| è§£é‡ˆæ€§ | LOF, çµ±è¨ˆçš„æ‰‹æ³•, DBSCAN | ç²¾åº¦ãƒ»é€Ÿåº¦ |
| æ–°ãƒ‡ãƒ¼ã‚¿äºˆæ¸¬ | One-Class SVM, Isolation Forest | - |
| ã‚ªãƒ³ãƒ©ã‚¤ãƒ³å­¦ç¿’ | Incremental PCA, ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ‰‹æ³• | ç²¾åº¦ |
| ãƒ­ãƒã‚¹ãƒˆæ€§ | Isolation Forest | è§£é‡ˆæ€§ |
| å°‘ãªã„èª¿æ•´ | Isolation Forest | æœ€é©æ€§ |

### ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹åˆ¥æ¨å¥¨

| ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹ | æ¨å¥¨æ‰‹æ³• | ç†ç”± |
|------------|---------|------|
| è£½é€ æ¥­ï¼ˆå“è³ªç®¡ç†ï¼‰ | One-Class SVM | é«˜ç²¾åº¦ã€æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ |
| ä¸æ­£æ¤œçŸ¥ï¼ˆé‡‘èï¼‰ | Isolation Forest, Autoencoder | å¤§è¦æ¨¡ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ  |
| ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼ˆä¾µå…¥æ¤œçŸ¥ï¼‰ | One-Class SVM, LOF | ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’ |
| IoTã‚»ãƒ³ã‚µãƒ¼ç•°å¸¸ | Isolation Forest, çµ±è¨ˆçš„æ‰‹æ³• | ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° |
| åŒ»ç™‚è¨ºæ–­ | One-Class SVM, Autoencoder | é«˜ç²¾åº¦ã€èª¬æ˜å¯èƒ½æ€§ |
| ãƒ­ã‚°ç›£è¦– | Isolation Forest | é«˜æ¬¡å…ƒã€é«˜é€Ÿ |
| ç”»åƒæ¤œæŸ» | Autoencoderï¼ˆCNNï¼‰ | ç©ºé–“ãƒ‘ã‚¿ãƒ¼ãƒ³ |

---

## å®Ÿè£…ä¾‹

### è¤‡æ•°æ‰‹æ³•ã®æ¯”è¼ƒ

```python
import numpy as np
from sklearn.svm import OneClassSVM
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
from sklearn.covariance import EllipticEnvelope
from sklearn.datasets import load_iris

# ãƒ‡ãƒ¼ã‚¿æº–å‚™
X = load_iris().data

# 1. One-Class SVM
ocs = OneClassSVM(nu=0.1, gamma='auto')
ocs_pred = ocs.fit_predict(X)

# 2. Isolation Forest
iforest = IsolationForest(contamination=0.1, random_state=42)
if_pred = iforest.fit_predict(X)

# 3. LOF
lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)
lof_pred = lof.fit_predict(X)

# 4. Gaussian (Elliptic Envelope)
ee = EllipticEnvelope(contamination=0.1)
ee_pred = ee.fit_predict(X)

# çµæœæ¯”è¼ƒ
methods = {
    "One-Class SVM": ocs_pred,
    "Isolation Forest": if_pred,
    "LOF": lof_pred,
    "Elliptic Envelope": ee_pred
}

for name, pred in methods.items():
    n_outliers = np.sum(pred == -1)
    print(f"{name:20s}: {n_outliers:3d} outliers ({n_outliers/len(X)*100:.1f}%)")
```

### å®Ÿè¡Œçµæœä¾‹

```
One-Class SVM       :  14 outliers (9.3%)
Isolation Forest    :  15 outliers (10.0%)
LOF                 :  15 outliers (10.0%)
Elliptic Envelope   :  15 outliers (10.0%)
```

### æ€§èƒ½æ¯”è¼ƒã‚³ãƒ¼ãƒ‰

```python
import time
from sklearn.metrics import confusion_matrix, classification_report

# äººå·¥çš„ã«ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
from sklearn.datasets import make_blobs
X_normal, _ = make_blobs(n_samples=200, centers=1, random_state=42)
X_anomaly = np.random.uniform(low=-10, high=10, size=(20, 2))
X = np.vstack([X_normal, X_anomaly])
y_true = np.array([1]*200 + [-1]*20)  # 1: æ­£å¸¸, -1: ç•°å¸¸

methods = {
    "One-Class SVM": OneClassSVM(nu=0.1),
    "Isolation Forest": IsolationForest(contamination=0.1, random_state=42),
}

for name, clf in methods.items():
    # å­¦ç¿’æ™‚é–“æ¸¬å®š
    start = time.time()
    y_pred = clf.fit_predict(X)
    elapsed = time.time() - start

    # è©•ä¾¡
    cm = confusion_matrix(y_true, y_pred)
    print(f"\n{name}")
    print(f"  å­¦ç¿’æ™‚é–“: {elapsed:.4f}ç§’")
    print(f"  æ··åŒè¡Œåˆ—:\n{cm}")
```

---

## ãƒ¦ãƒ¼ã‚¹ã‚±ãƒ¼ã‚¹

### One-Class SVMãŒæœ€é©ãªå ´åˆ

#### 1. è£½é€ æ¥­ã®å“è³ªç®¡ç†
- **çŠ¶æ³**: æ­£å¸¸å“ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿å¤§é‡ã«ã‚ã‚‹ã€ä¸è‰¯å“ã®ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„
- **ç†ç”±**:
  - é«˜ç²¾åº¦ãªå¢ƒç•Œå­¦ç¿’
  - æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§å­¦ç¿’å¯èƒ½
  - ã‚«ãƒ¼ãƒãƒ«ã§è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹
- **ä¾‹**: åŠå°ä½“æ¤œæŸ»ã€æº¶æ¥å“è³ªãƒã‚§ãƒƒã‚¯

#### 2. åŒ»ç™‚è¨ºæ–­
- **çŠ¶æ³**: å¥åº·ãªäººã®ãƒ‡ãƒ¼ã‚¿ã¯è±Šå¯Œã€ç—…æ°—ã®ãƒ‡ãƒ¼ã‚¿ã¯å°‘ãªã„
- **ç†ç”±**:
  - é«˜ã„ç²¾åº¦ãŒè¦æ±‚ã•ã‚Œã‚‹
  - èª¤æ¤œçŸ¥ï¼ˆå½é™½æ€§ï¼‰ã®ã‚³ã‚¹ãƒˆãŒé«˜ã„
- **ä¾‹**: å¿ƒé›»å›³ç•°å¸¸æ¤œçŸ¥ã€MRIç”»åƒè¨ºæ–­

#### 3. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼ˆä¾µå…¥æ¤œçŸ¥ï¼‰
- **çŠ¶æ³**: æ­£å¸¸ãªé€šä¿¡ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã€ç•°å¸¸ãªé€šä¿¡ã‚’æ¤œå‡º
- **ç†ç”±**:
  - è¤‡é›‘ãªæ”»æ’ƒãƒ‘ã‚¿ãƒ¼ãƒ³ã«å¯¾å¿œ
  - ç²¾åº¦é‡è¦–
- **ä¾‹**: ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ä¾µå…¥æ¤œçŸ¥ã€èªè¨¼ã‚·ã‚¹ãƒ†ãƒ 

---

### Isolation ForestãŒæœ€é©ãªå ´åˆ

#### 1. ä¸æ­£æ¤œçŸ¥ï¼ˆã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ï¼‰
- **çŠ¶æ³**: å¤§é‡ã®ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†
- **ç†ç”±**:
  - é«˜é€Ÿå‡¦ç†
  - ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«
  - é«˜æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ã«å¼·ã„
- **ä¾‹**: ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆã‚«ãƒ¼ãƒ‰ä¸æ­£åˆ©ç”¨æ¤œçŸ¥ã€ä¿é™ºé‡‘è©æ¬ºæ¤œçŸ¥

#### 2. ãƒ­ã‚°ç•°å¸¸æ¤œçŸ¥
- **çŠ¶æ³**: å¤§é‡ã®ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿ã€å¤šæ¬¡å…ƒ
- **ç†ç”±**:
  - é«˜é€Ÿå‡¦ç†
  - ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´ãŒç°¡å˜
- **ä¾‹**: ã‚µãƒ¼ãƒãƒ¼ãƒ­ã‚°ç›£è¦–ã€ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚°åˆ†æ

---

### AutoencoderãŒæœ€é©ãªå ´åˆ

#### 1. ç”»åƒæ¤œæŸ»
- **çŠ¶æ³**: æ­£å¸¸ç”»åƒã®ã¿ã§å­¦ç¿’ã€å‚·ã‚„æ¬ é™¥ã‚’æ¤œå‡º
- **ç†ç”±**:
  - CNNã§ç©ºé–“æ§‹é€ ã‚’ä¿æŒ
  - è¤‡é›‘ãªéç·šå½¢ãƒ‘ã‚¿ãƒ¼ãƒ³å­¦ç¿’
- **ä¾‹**: è£½å“å¤–è¦³æ¤œæŸ»ã€Xç·šæ¤œæŸ»

#### 2. æ™‚ç³»åˆ—ç•°å¸¸æ¤œçŸ¥
- **çŠ¶æ³**: ã‚»ãƒ³ã‚µãƒ¼ãƒ‡ãƒ¼ã‚¿ã€è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³
- **ç†ç”±**:
  - LSTMã§æ™‚é–“ä¾å­˜æ€§ã‚’å­¦ç¿’
  - é•·æœŸçš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ‰ãˆã‚‹
- **ä¾‹**: è¨­å‚™æ•…éšœäºˆçŸ¥ã€æ ªä¾¡ç•°å¸¸æ¤œçŸ¥

---

## å­¦ç¿’ãƒ¡ãƒ¢

### One-Class SVMã‚’é¸ã‚“ã ç†ç”±ï¼ˆ05_iris_sklearn_outlierï¼‰

1. **æ•™å¸«ãªã—å­¦ç¿’ã®åŸºç¤ã‚’å­¦ã¶ãŸã‚**
   - ãƒ©ãƒ™ãƒ«ãªã—ã§ã®å­¦ç¿’ä½“é¨“
   - æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‹ã‚‰ã®å­¦ç¿’

2. **SVMã®å¿œç”¨ã‚’ç†è§£ã™ã‚‹ãŸã‚**
   - åˆ†é¡SVMã¨ã®é•ã„
   - ã‚«ãƒ¼ãƒãƒ«ãƒˆãƒªãƒƒã‚¯ã®å¿œç”¨

3. **ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã®çµŒé¨“**
   - nuã®å½±éŸ¿ã‚’ç†è§£
   - gammaã®å½±éŸ¿ã‚’ç†è§£

4. **å®Ÿå‹™ã§é‡è¦ãªãƒ‘ã‚¿ãƒ¼ãƒ³**
   - ç•°å¸¸ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã„çŠ¶æ³ã¯ç¾å®Ÿçš„
   - è£½é€ æ¥­ãƒ»åŒ»ç™‚ãªã©å¹…åºƒã„å¿œç”¨

### ä»Šå¾Œã®å­¦ç¿’èª²é¡Œ

- [ ] Isolation Forestã®å®Ÿè£…ã¨æ¯”è¼ƒ
- [ ] Autoencoderã«ã‚ˆã‚‹ç”»åƒç•°å¸¸æ¤œçŸ¥ï¼ˆ06_cifar10ã§å­¦ç¿’äºˆå®šï¼‰
- [ ] LOFã¨ã®æ€§èƒ½æ¯”è¼ƒ
- [ ] å®Ÿãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡

---

## å‚è€ƒè³‡æ–™

### è«–æ–‡
- SchÃ¶lkopf et al. (2001) "Estimating the Support of a High-Dimensional Distribution"
- Liu et al. (2008) "Isolation Forest"
- Breunig et al. (2000) "LOF: Identifying Density-Based Local Outliers"

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- [scikit-learn: Novelty and Outlier Detection](https://scikit-learn.org/stable/modules/outlier_detection.html)
- [scikit-learn: OneClassSVM](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html)
- [scikit-learn: IsolationForest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html)

### å®Ÿè£…
- [05_iris_sklearn_outlier](../03_my_implementations/chapter2_training/05_iris_sklearn_outlier/)
- [å‚è€ƒå®Ÿè£…](../01_reference/chapter2_training/iris_sklearn_outlier/)

---

**æ›´æ–°å±¥æ­´**:
- 2025-11-05: åˆç‰ˆä½œæˆ
